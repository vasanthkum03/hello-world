{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQUcieLXIKIIJDP3nhOLki",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasanthkum03/hello-world/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "!pip install pyspark"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgh47lpuDx0c",
        "outputId": "32d27a60-f269-495d-f761-a519d523ef99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window # Import Window class from pyspark.sql.window\n",
        "import pyspark.sql.functions as F # Import functions for sum\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"MySparkApp\").getOrCreate()\n",
        "\n",
        "data = [(1,\"HR\",50000,\"2022-01-01\"),(2,\"IT\",70000,\"2021-06-15\"),(3,\"HR\",60000,\"2023-03-10\"),(4,\"IT\",80000,\"2020-12-01\")]\n",
        "columns = [\"employee_id\",\"department\",\"salary\",\"join_date\"]\n",
        "\n",
        "df = spark.createDataFrame(data,columns)\n",
        "df.show()\n",
        "WindowSpec = Window.partitionBy(\"department\").orderBy(\"join_date\")\n",
        "# Remove .show() from the end to assign the transformed DataFrame to df1\n",
        "df1 = df.withColumn(\"cumulative_salary\",F.sum(\"salary\").over(WindowSpec))\n",
        "df1.show() # Display df1\n",
        "\n",
        "# Remove .show() from the end to assign the transformed DataFrame to df2\n",
        "df2 = df1.withColumn(\"rank\",F.rank().over(WindowSpec))\n",
        "df2.show() # Display df2"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74V-0UMwIiPb",
        "outputId": "1f0fd3e0-ae39-4313-da13-6bb65b7be53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+------+----------+\n",
            "|employee_id|department|salary| join_date|\n",
            "+-----------+----------+------+----------+\n",
            "|          1|        HR| 50000|2022-01-01|\n",
            "|          2|        IT| 70000|2021-06-15|\n",
            "|          3|        HR| 60000|2023-03-10|\n",
            "|          4|        IT| 80000|2020-12-01|\n",
            "+-----------+----------+------+----------+\n",
            "\n",
            "+-----------+----------+------+----------+-----------------+\n",
            "|employee_id|department|salary| join_date|cumulative_salary|\n",
            "+-----------+----------+------+----------+-----------------+\n",
            "|          1|        HR| 50000|2022-01-01|            50000|\n",
            "|          3|        HR| 60000|2023-03-10|           110000|\n",
            "|          4|        IT| 80000|2020-12-01|            80000|\n",
            "|          2|        IT| 70000|2021-06-15|           150000|\n",
            "+-----------+----------+------+----------+-----------------+\n",
            "\n",
            "+-----------+----------+------+----------+-----------------+----+\n",
            "|employee_id|department|salary| join_date|cumulative_salary|rank|\n",
            "+-----------+----------+------+----------+-----------------+----+\n",
            "|          1|        HR| 50000|2022-01-01|            50000|   1|\n",
            "|          3|        HR| 60000|2023-03-10|           110000|   2|\n",
            "|          4|        IT| 80000|2020-12-01|            80000|   1|\n",
            "|          2|        IT| 70000|2021-06-15|           150000|   2|\n",
            "+-----------+----------+------+----------+-----------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window # Import Window class from pyspark.sql.window\n",
        "import pyspark.sql.functions as F # Import functions for sum\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"MySparkApp\").getOrCreate()\n",
        "\n",
        "data = [(\"Store A\",\"2024-01\",800),(\"Store A\",\"2024-02\",1200),(\"Store A\",\"2024-03\",900),(\"Store B\",\"2024-01\",1500),(\"Store B\",\"2024-02\",1600)\n",
        ",(\"Store B\",\"2024-03\",1400),(\"Store C\",\"2024-01\",700),(\"Store C\",\"2024-02\",1000),(\"Store C\",\"2024-03\",800)]\n",
        "columns = [\"Store\",\"Month\",\"Sales\"]\n",
        "\n",
        "dfa = spark.createDataFrame(data,columns)\n",
        "\n",
        "\n",
        "df=dfa.filter(F.col(\"Sales\")>=1000)\n",
        "df.show()\n",
        "windowSpec = Window.partitionBy(\"Store\").orderBy(\"Month\")\n",
        "df1 = df.withColumn(\"Cumulative_Sales\",F.sum(\"Sales\").over(windowSpec))\n",
        "df1.show()\n",
        "\n",
        "df2 = df1.groupby(\"Store\").agg(F.sum(\"Sales\").alias(\"Total_Sales\"))\n",
        "df2.show()\n",
        "df_final = df1.join(df2,on = \"Store\").select(\"Store\",\"Total_Sales\",\"Cumulative_Sales\")\n",
        "df_result = df_final.orderBy(F.col(\"Total_Sales\").desc())\n",
        "df_result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i13qFuQcJe5l",
        "outputId": "bb82e5c1-b1c0-4951-ec2a-0d5b2a66759f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----+\n",
            "|  Store|  Month|Sales|\n",
            "+-------+-------+-----+\n",
            "|Store A|2024-02| 1200|\n",
            "|Store B|2024-01| 1500|\n",
            "|Store B|2024-02| 1600|\n",
            "|Store B|2024-03| 1400|\n",
            "|Store C|2024-02| 1000|\n",
            "+-------+-------+-----+\n",
            "\n",
            "+-------+-------+-----+----------------+\n",
            "|  Store|  Month|Sales|Cumulative_Sales|\n",
            "+-------+-------+-----+----------------+\n",
            "|Store A|2024-02| 1200|            1200|\n",
            "|Store B|2024-01| 1500|            1500|\n",
            "|Store B|2024-02| 1600|            3100|\n",
            "|Store B|2024-03| 1400|            4500|\n",
            "|Store C|2024-02| 1000|            1000|\n",
            "+-------+-------+-----+----------------+\n",
            "\n",
            "+-------+-----------+\n",
            "|  Store|Total_Sales|\n",
            "+-------+-----------+\n",
            "|Store B|       4500|\n",
            "|Store A|       1200|\n",
            "|Store C|       1000|\n",
            "+-------+-----------+\n",
            "\n",
            "+-------+-----------+----------------+\n",
            "|  Store|Total_Sales|Cumulative_Sales|\n",
            "+-------+-----------+----------------+\n",
            "|Store B|       4500|            4500|\n",
            "|Store B|       4500|            3100|\n",
            "|Store B|       4500|            1500|\n",
            "|Store A|       1200|            1200|\n",
            "|Store C|       1000|            1000|\n",
            "+-------+-----------+----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}